import os
import matplotlib.pyplot as plt
import torch
from demos.utils import save_simulation, create_scientific_subplot_plot
from pbd_torch.collision import collide
from pbd_torch.constants import ROT_IDENTITY
from pbd_torch.model import Model
from pbd_torch.model import Quaternion
from pbd_torch.model import Vector3
from pbd_torch.newton_engine import NonSmoothNewtonEngine
from pbd_torch.terrain import create_terrain_from_exr_file
from tqdm import tqdm
from pbd_torch.xpbd_engine import XPBDEngine

PARAM = "pos_z" # Choose from ["pos_x", "pos_y", "pos_z", "vel_x", "vel_y", "vel_z"]
EXPERIMENT_NAME = "sphere_bounce_grad_pos_z2"

ENGINE = "newton"  # Choose from ["newton", "xpbd"]

AVAILABLE_PARAMS = {
    "pos_x": ("body_q", 0),
    "pos_y": ("body_q", 1),
    "pos_z": ("body_q", 2),
    "vel_x": ("body_qd", 3),
    "vel_y": ("body_qd", 4),
    "vel_z": ("body_qd", 5),
}

assert PARAM in AVAILABLE_PARAMS.keys(), "You must choose parameter form available parameters!"

# Initial state
INITIAL_POSITION = torch.tensor([-0.0, -0.0, 4.5]).view(3, 1)
INITIAL_VELOCITY = torch.tensor([5.0, 0.0, -5.0]).view(3, 1)

# Simulation Constants
MAX_CONTACTS_PER_BODY = 36
N_COLLISION_POINTS = 2000
RESTITUTION = 0.8
DYNAMIC_FRICTION = 0.8

# Get the current working directory
current_dir = os.path.dirname(os.path.abspath(__file__))
data_dir = os.path.join(current_dir, "..", "..", "..", "data")
experiment_dir = os.path.abspath(os.path.join(data_dir, EXPERIMENT_NAME))

# Output File Names
ANALYTICAL_GRAD_FILE = os.path.join(experiment_dir, "grad_analytical.pt")
NUMERICAL_GRAD_FILE = os.path.join(experiment_dir, "grad_numerical.pt")
LOSS_FILE = os.path.join(experiment_dir, "loss.pt")
PARAM_FILE = os.path.join(experiment_dir, f"{PARAM}.pt")
SIMULATION_FILE = os.path.join(experiment_dir, "simulation.json")

TERRAIN_FILE = os.path.join(data_dir, "blender", "ground4", "textures", "ant01.002_heightmap.exr")
PLOT_FILE = os.path.join(experiment_dir, "gradients_and_loss.png")

def create_model(device: torch.device) -> tuple[Model, int]:
    """Create a sphere model with specified parameters."""
    terrain = create_terrain_from_exr_file(
        heightmap_path=TERRAIN_FILE,
        size_x=40.0,
        size_y=40.0,
        device=device,
    )

    model = Model(max_contacts_per_body=MAX_CONTACTS_PER_BODY, gravity=False)

    sphere_idx = model.add_sphere(
        m=1.0,
        radius=1.0,
        name="sphere",
        pos=Vector3(INITIAL_POSITION.view(-1)),
        rot=Quaternion(ROT_IDENTITY),
        restitution=RESTITUTION,
        dynamic_friction=DYNAMIC_FRICTION,
        n_collision_points=N_COLLISION_POINTS,
    )
    return model, sphere_idx

def simulate_sphere(
    model: Model,
    sphere_idx: int,
    dt: float,
    n_steps: int,
    device: torch.device,
) -> torch.Tensor:
    model.body_q[sphere_idx, :3] = INITIAL_POSITION
    model.body_qd[sphere_idx, 3:] = INITIAL_VELOCITY

    if ENGINE == "xpbd":
        engine = XPBDEngine(model, pos_iters=10)
    elif ENGINE == "newton":
        engine = NonSmoothNewtonEngine(model, iterations=150)
    else:
        raise ValueError(f"Unknown engine: {ENGINE}")

    control = model.control()
    states = [model.state() for _ in range(n_steps)]

    for i in tqdm(range(n_steps - 1), desc="Simulating"):
        collide(model, states[i], collision_margin=0.0)

        if ENGINE == "xpbd":
            engine.simulate(states[i], states[i + 1], control, dt)
        elif ENGINE == "newton":
            engine.simulate_xitorch(states[i], states[i + 1], control, dt)
        else:
            raise ValueError(f"Unknown engine: {ENGINE}")

    target_transform = states[-1].body_q[sphere_idx].clone()
    print(f"Target transform: {target_transform}")
    print(f"Saving simulation to {SIMULATION_FILE}")
    save_simulation(model, states, SIMULATION_FILE)

    return target_transform

def compute_analytical_gradients(
    model: Model,
    sphere_idx: int,
    target_transform: torch.Tensor,
    dt: float,
    n_steps: int,
) -> torch.Tensor:
    losses = []
    gradients = []

    param_info = AVAILABLE_PARAMS[PARAM]
    model_attribute = param_info[0]
    param_idx = param_info[1]

    initial_param = getattr(model, model_attribute)[sphere_idx, param_idx].item()
    param_range = torch.linspace(initial_param - 1.2, initial_param + 1.2, 51)

    for p in tqdm(param_range):
        new_model_attribute = getattr(model, model_attribute).clone()
        new_model_attribute[sphere_idx, param_idx] = p
        setattr(model, model_attribute, new_model_attribute.detach().requires_grad_(True))

        if ENGINE == "xpbd":
            engine = XPBDEngine(model, pos_iters=10)
        elif ENGINE == "newton":
            engine = NonSmoothNewtonEngine(model, iterations=150)
        else:
            raise ValueError(f"Unknown engine: {ENGINE}")

        control = model.control()
        states = [model.state() for _ in range(n_steps)]

        for j in range(n_steps - 1):
            collide(model, states[j], collision_margin=0.0)

            if ENGINE == "xpbd":
                engine.simulate(states[j], states[j + 1], control, dt)
            elif ENGINE == "newton":
                engine.simulate_xitorch(states[j], states[j + 1], control, dt)
            else:
                raise ValueError(f"Unknown engine: {ENGINE}")

        loss = compute_loss(states[-1].body_q[sphere_idx], target_transform)
        loss.backward()
        analytical_gradient = getattr(model, model_attribute).grad[sphere_idx, param_idx]

        gradients.append(analytical_gradient.item())
        losses.append(loss.item())
        if model.body_q.grad is not None:
            model.body_q.grad.zero_()
        if model.body_qd.grad is not None:
            model.body_qd.grad.zero_()

    torch.save(torch.tensor(gradients), ANALYTICAL_GRAD_FILE)
    torch.save(torch.tensor(losses), LOSS_FILE)
    torch.save(param_range, PARAM_FILE)
    return torch.tensor(gradients)

@torch.no_grad()
def compute_numerical_gradients(
    model: Model,
    sphere_idx: int,
    target_transform: torch.Tensor,
    dt: float,
    n_steps: int,
    epsilon: float = 1e-4,
) -> torch.Tensor:
    losses = []
    gradients = []

    param_info = AVAILABLE_PARAMS[PARAM]
    model_attribute = param_info[0]
    param_idx = param_info[1]

    initial_param = getattr(model, model_attribute)[sphere_idx, param_idx].item()
    param_range = torch.linspace(initial_param - 1.0, initial_param + 1.0, 31)

    for p in param_range:
        engine = NonSmoothNewtonEngine(model, iterations=50)
        control = model.control()

        new_model_attribute = getattr(model, model_attribute).clone()
        new_model_attribute[sphere_idx, param_idx] = p
        setattr(model, model_attribute, new_model_attribute)
        states = [model.state() for _ in range(n_steps)]
        for j in range(n_steps - 1):
            collide(model, states[j], collision_margin=0.0)
            engine.simulate_xitorch(states[j], states[j + 1], control, dt)

        loss_original = compute_loss(getattr(states[-1], model_attribute)[sphere_idx], target_transform)

        # Perturbed simulation
        perturbed_model_attribute = getattr(model, model_attribute).clone()
        perturbed_model_attribute[sphere_idx, param_idx] = p + epsilon
        setattr(model, model_attribute, perturbed_model_attribute)
        states_perturbed = [model.state() for _ in range(n_steps)]
        for j in range(n_steps - 1):
            collide(model, states_perturbed[j], collision_margin=0.0)
            engine.simulate_xitorch(
                states_perturbed[j], states_perturbed[j + 1], control, dt
            )

        loss_perturbed = compute_loss(getattr(states_perturbed[-1], model_attribute)[sphere_idx], target_transform)
        numerical_gradient = (loss_perturbed - loss_original) / epsilon

        print(
            f"\nComputing numerical gradient for {PARAM}={p:.2f}\n"
            f"\tOriginal Loss: {loss_original.item():.4f}\n"
            f"\tPerturbed Loss: {loss_perturbed.item():.4f}\n"
            f"\tGradient: {numerical_gradient.item():.4f}"
        )

        gradients.append(numerical_gradient.item())
        losses.append(loss_original.item())

    torch.save(torch.tensor(gradients), NUMERICAL_GRAD_FILE)
    return torch.tensor(gradients)

def compute_loss(body_q: torch.Tensor, target_body_q: torch.Tensor) -> torch.Tensor:
    """Compute the loss between the current and target transforms."""
    # return torch.norm(body_q[param_idx] - target_body_q[param_idx], p=2)
    return torch.sum((body_q[:3] - target_body_q[:3])**2)


def compute_gradients(
    model: Model,
    sphere_idx: int,
    target_transform: torch.Tensor,
    dt: float,
    n_steps: int,
) -> None:
    """Compute and save both analytical and numerical gradients."""
    compute_analytical_gradients(
        model, sphere_idx, target_transform, dt, n_steps
    )

def visualize_gradients(
    param_file: str = PARAM_FILE,
    loss_file: str = LOSS_FILE,
    analytical_grad_file: str = ANALYTICAL_GRAD_FILE,
    numerical_grad_file: str = NUMERICAL_GRAD_FILE,
) -> None:
    """Visualize loss and gradient data using scientific subplot plot."""
    # Load data
    params = torch.load(param_file)
    loss = torch.load(loss_file)
    analytical_grad = torch.load(analytical_grad_file)
    try:
        numerical_grad = torch.load(numerical_grad_file)
    except FileNotFoundError:
        numerical_grad = None
        print(f"Warning: Numerical gradient file {numerical_grad_file} not found. Plotting only analytical gradients.")

    # Enable LaTeX rendering
    tex_config_setup = {
        'use_tex': True,
        'fonts': 'serif',
        'fontsize': 12,
        'custom_preamble': True,
        'preamble': r'\usepackage{amsmath,amssymb,amsfonts}\usepackage{physics}\usepackage{siunitx}'
    }
    if tex_config_setup['use_tex']:
        plt.rcParams.update({
            "text.usetex": True,
            "font.family": tex_config_setup['fonts'],
            "font.size": tex_config_setup['fontsize']
        })
        if tex_config_setup['custom_preamble'] and tex_config_setup['preamble']:
            plt.rcParams["text.latex.preamble"] = tex_config_setup['preamble']

    # Prepare plot data
    plot_data = {
        'Loss': {
            'loss_series': {
                'data': loss.numpy(),
                'label': r'Loss',
                'color': '#1f77b4', # Blue
                'linewidth': 2.0,
                'alpha': 1.0
            }
        },
        'Analytical Gradient': {
            'analytical_grad_series': {
                'data': analytical_grad.numpy(),
                'label': r'$\displaystyle\pdv{l}{x_z^0}$',
                'color': '#ff7f0e', # Orange
                'linewidth': 2.0,
                'alpha': 1.0
            }
        }
    }

    y_labels = {
        'Loss': r'Loss (-)',
        'Analytical Gradient': r'$\displaystyle\pdv{l}{x_z^0}$ (-)'
    }

    plot_titles = {
        'Loss': r'Loss vs. Initial $z$-Position',
        'Analytical Gradient': r'Gradient vs. Initial $z$-Position'
    }

    if numerical_grad is not None:
        plot_data['Numerical Gradient'] = {
            'numerical_grad_series': {
                'data': numerical_grad.numpy(),
                'label': r'$\displaystyle\pdv{l}{x_z^0}$ (Numerical)',
                'color': 'red',
                'linewidth': 2.0,
                'alpha': 1.0,
                'linestyle': '--'
            }
        }
        y_labels['Numerical Gradient'] = r'$\displaystyle\pdv{l}{x_z^0}$ (-)'
        plot_titles['Numerical Gradient'] = r'Numerical Gradient vs. Initial $z$-Position'

    # Plot configuration
    n_subplots = 3 if numerical_grad is not None else 2
    plot_config = {
        'plot_arrangement': 'horizontal',
        'figsize': (5 * n_subplots, 5),
        'suptitle': '',
        'x_label': r'Initial $z$-Position $x_z^0$ (m)',
        'y_labels': y_labels,
        'plot_titles': plot_titles,
        'shared_x': True,
        'shared_y': False,
        'dpi': 200,
        'legend': {'show': True, 'location': 'best', 'fontsize': 13},
        'grid': {'show': True, 'linestyle': '--', 'alpha': 0.8},
        'font_sizes': {'axis_label': 13, 'tick_label': 13, 'title': 13, 'suptitle': 14},
        'tight_layout_params': {'rect': [0, 0.02, 1, 0.95]}
    }

    # Create and save the plot
    fig, _ = create_scientific_subplot_plot(
        time_data=params.numpy(),
        plot_data=plot_data,
        config=plot_config,
        save_path=PLOT_FILE
    )
    print(f"Scientific plot saved to {PLOT_FILE}")
    plt.close(fig)

def main():
    dt = 0.005
    n_steps = 200
    device = torch.device("cpu")

    # Initialize model and sphere
    model, sphere_idx = create_model(device)

    os.makedirs(experiment_dir, exist_ok=True)

    # Run simulation
    target_transform = simulate_sphere(model, sphere_idx, dt, n_steps, device)

    # Compute gradients
    compute_gradients(model, sphere_idx, target_transform, dt, n_steps)

    # Visualize results
    visualize_gradients()

if __name__ == "__main__":
    main()